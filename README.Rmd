---
title: "Entendiendo El Teorema del Límite Central"
output: html_document
markdown: kramdown

kramdown:
  input: GFM
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Un análisis basado en:

https://lambdaclass.com/data_etudes/central_limit_theorem_misuse/

El teorema del límite central (TCL) es, posiblemente, uno de los teoremas más famosos de toda la estadística, y se usa ampliamente en cualquier campo en el que se quiera inferir algo o hacer predicciones a partir de los datos recopilados. Una primera versión (simple) fue introducida en el siglo XVIII, primero por De Moivre y luego de una manera más refinada por Laplace, pero no fue hasta alrededor de 1935 que se publicó el teorema tal y como lo conocemos hoy. El objetivo de estas notas didácticas es explicar, en términos generales lo que dice y, lo que es más importante, *lo que no dice*.

De manera informal, el teorema establece que si tomamos muestras aleatorias de una determinada distribución y luego las promediamos, el resultado (es decir, la media de la muestra) se parecerá a una distribución normal cuantas más muestras tomemos. De forma más precisa, si ${X_{1},...,X_{n},...}$ son variables aleatorias independientes e idénticamente distribuidas *(i.i.d)* y $\overline{X}_{n}=\big(X_{1}+...+X_{n}\big)/n$ es la media muestral, su normalización (estandarización) $\dfrac{\overline{X}_{n}-E(\overline{X}_{n})}{\sqrt{Var(\overline{X}_{n})}}$ converge (en distribución) con una distribución normal estándar $N(0,1)$.

